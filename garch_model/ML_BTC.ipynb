{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "042c9b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import pyextremes as pyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "827d61e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_estimator(data, k):\n",
    "    log_data = np.log(data[:k])\n",
    "    return (1/k) * np.sum(log_data) - np.log(data[k])\n",
    "\n",
    "def pickands_estimator(data, k):\n",
    "    if 4*k >= len(data):\n",
    "        return np.nan\n",
    "    return 1/np.log(2) * np.log((data[k] - data[2*k])/(data[2*k] - data[4*k]))\n",
    "\n",
    "def threshold_picking(data0):\n",
    "    data = -data0[data0 < 0]\n",
    "    thresholds = np.linspace(data.quantile(0.2), data.quantile(0.995), 200)\n",
    "    pyx.plot_mean_residual_life(data, thresholds=thresholds)\n",
    "    datas = np.sort(data)[::-1]\n",
    "    k_values = range(4, int(len(datas)/1.3))\n",
    "\n",
    "    hill_estimates = [hill_estimator(datas, k) for k in k_values]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(k_values, hill_estimates, 'b-')\n",
    "\n",
    "    pickands_estimates = [pickands_estimator(datas, k) for k in k_values]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(k_values, pickands_estimates, 'r-', label=\"Pickands' ξ\")\n",
    "    return datas\n",
    "\n",
    "def modeling(data0, u):\n",
    "    data = -data0[data0 < 0]\n",
    "    model = pyx.EVA(data)\n",
    "    model.get_extremes(method=\"POT\", threshold=u)\n",
    "    model.fit_model(distribution=\"genpareto\")\n",
    "    print(model.model)\n",
    "    model.plot_diagnostic()\n",
    "\n",
    "    params = model.model.fit_parameters\n",
    "    print(params)\n",
    "    xi = params['c']\n",
    "    sig = params['scale']\n",
    "    return xi, sig\n",
    "\n",
    "def prediction(params, data, u, level):\n",
    "    xi = params[0]\n",
    "    sig = params[1]\n",
    "    data = -data\n",
    "    p = level\n",
    "    n_total = len(data)\n",
    "    n_exceed = len([i for i in data if i > u])\n",
    "    F_u = n_exceed / n_total\n",
    "    print(F_u)\n",
    "    p_u = F_u / p\n",
    "    VaR = u + (sig / xi) * (p_u ** xi - 1)\n",
    "    ES = ES = (VaR + (sig - xi * u)) / (1 - xi)\n",
    "    return VaR, ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e4eac8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:      5,   Func. Count:     40,   Neg. LLF: -7891.360700449592\n",
      "Iteration:     10,   Func. Count:     70,   Neg. LLF: -8055.905940454345\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: -8055.938362738767\n",
      "            Iterations: 14\n",
      "            Function evaluations: 95\n",
      "            Gradient evaluations: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\arch\\univariate\\base.py:309: DataScaleWarning: y is poorly scaled, which may affect convergence of the optimizer when\n",
      "estimating the model parameters. The scale of y is 0.001467. Parameter\n",
      "estimation work better when this value is between 1 and 1000. The recommended\n",
      "rescaling is 10 * y.\n",
      "\n",
      "This warning can be disabled by either rescaling y before initializing the\n",
      "model or by setting rescale=False.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "data = pd.read_csv(\"../data/btc_daily_data.csv\")\n",
    "data.set_index(\"Date\", inplace=True)\n",
    "data = data['Close'][715:]\n",
    "data.index = pd.to_datetime(data.index).normalize()\n",
    "returns = np.log(data / data.shift(1)).dropna()\n",
    "\n",
    "# Create volatility proxy (squared returns)\n",
    "#volatility = returns ** 2\n",
    "\n",
    "#Create volatility proxy (garch fitted)\n",
    "from arch import arch_model\n",
    "garch = arch_model(returns, vol=\"GARCH\", p=1, q=1)\n",
    "garch_fit = garch.fit(update_freq=5)\n",
    "volatility = garch_fit.conditional_volatility\n",
    "\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_vol = scaler.fit_transform(volatility.values.reshape(-1, 1))\n",
    "\n",
    "# Split data 50:50\n",
    "split_idx = len(scaled_vol) // 2\n",
    "train_vol, test_vol = scaled_vol[:split_idx], scaled_vol[split_idx:]\n",
    "train_returns, test_returns = returns[:split_idx], returns[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47cb716a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 20  # Lookback window\n",
    "X_train, y_train = create_sequences(train_vol, seq_length)\n",
    "X_test, y_test = create_sequences(test_vol, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78a59f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0111 - mae: 0.0731 - val_loss: 0.0033 - val_mae: 0.0320\n",
      "Epoch 2/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0048 - mae: 0.0472 - val_loss: 0.0027 - val_mae: 0.0285\n",
      "Epoch 3/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0038 - mae: 0.0426 - val_loss: 0.0025 - val_mae: 0.0261\n",
      "Epoch 4/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0036 - mae: 0.0397 - val_loss: 0.0022 - val_mae: 0.0246\n",
      "Epoch 5/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0031 - mae: 0.0363 - val_loss: 0.0020 - val_mae: 0.0235\n",
      "Epoch 6/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0029 - mae: 0.0357 - val_loss: 0.0019 - val_mae: 0.0221\n",
      "Epoch 7/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0027 - mae: 0.0332 - val_loss: 0.0018 - val_mae: 0.0210\n",
      "Epoch 8/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0025 - mae: 0.0319 - val_loss: 0.0017 - val_mae: 0.0205\n",
      "Epoch 9/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0025 - mae: 0.0305 - val_loss: 0.0016 - val_mae: 0.0195\n",
      "Epoch 10/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0024 - mae: 0.0303 - val_loss: 0.0016 - val_mae: 0.0191\n",
      "Epoch 11/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0021 - mae: 0.0277 - val_loss: 0.0015 - val_mae: 0.0195\n",
      "Epoch 12/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: 0.0022 - mae: 0.0285 - val_loss: 0.0014 - val_mae: 0.0189\n",
      "Epoch 13/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0021 - mae: 0.0278 - val_loss: 0.0014 - val_mae: 0.0190\n",
      "Epoch 14/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0019 - mae: 0.0268 - val_loss: 0.0013 - val_mae: 0.0183\n",
      "Epoch 15/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0257 - val_loss: 0.0013 - val_mae: 0.0175\n",
      "Epoch 16/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0255 - val_loss: 0.0013 - val_mae: 0.0188\n",
      "Epoch 17/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0260 - val_loss: 0.0013 - val_mae: 0.0172\n",
      "Epoch 18/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.0018 - mae: 0.0253 - val_loss: 0.0013 - val_mae: 0.0182\n",
      "Epoch 19/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0253 - val_loss: 0.0013 - val_mae: 0.0187\n",
      "Epoch 20/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0018 - mae: 0.0251 - val_loss: 0.0013 - val_mae: 0.0177\n",
      "Epoch 21/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0246 - val_loss: 0.0013 - val_mae: 0.0169\n",
      "Epoch 22/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0017 - mae: 0.0245 - val_loss: 0.0013 - val_mae: 0.0166\n",
      "Epoch 23/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0017 - mae: 0.0244 - val_loss: 0.0013 - val_mae: 0.0157\n",
      "Epoch 24/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0236 - val_loss: 0.0013 - val_mae: 0.0167\n",
      "Epoch 25/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0241 - val_loss: 0.0013 - val_mae: 0.0181\n",
      "Epoch 26/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0016 - mae: 0.0241 - val_loss: 0.0013 - val_mae: 0.0163\n",
      "Epoch 27/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0017 - mae: 0.0247 - val_loss: 0.0013 - val_mae: 0.0179\n",
      "Epoch 28/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0015 - mae: 0.0236 - val_loss: 0.0013 - val_mae: 0.0183\n",
      "Epoch 29/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0018 - mae: 0.0249 - val_loss: 0.0013 - val_mae: 0.0167\n",
      "Epoch 30/100\n",
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0016 - mae: 0.0238 - val_loss: 0.0013 - val_mae: 0.0185\n"
     ]
    }
   ],
   "source": [
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, activation='tanh', return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.3),\n",
    "        LSTM(32, activation='tanh'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "model = build_lstm_model(input_shape)\n",
    "\n",
    "# Train with early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "756209d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "              MLE model              \n",
      "-------------------------------------\n",
      "free parameters: c=0.116, scale=0.785\n",
      "fixed parameters: floc=1.295         \n",
      "AIC: 206.870                         \n",
      "loglikelihood: -101.382              \n",
      "return value cache size: 0           \n",
      "fit parameter cache size: 0          \n",
      "-------------------------------------\n",
      "{'c': 0.1164369674876734, 'scale': 0.7846673121388967}\n",
      "0.06394490900147565\n",
      "2.9197052368248317\n",
      "[-0.12551305 -0.12288593 -0.12787776 ... -0.12247348 -0.11542814\n",
      " -0.10826997]\n",
      "Date\n",
      "2019-08-01    0.020930\n",
      "2019-08-02    0.053605\n",
      "2019-08-03    0.032379\n",
      "2019-08-04   -0.017798\n",
      "2019-08-05    0.085321\n",
      "                ...   \n",
      "2025-03-10   -0.036496\n",
      "2025-03-11   -0.013324\n",
      "2025-03-12    0.016279\n",
      "2025-03-13    0.008791\n",
      "2025-03-14   -0.007800\n",
      "Freq: D, Name: Close, Length: 2053, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "volatility_forecasts = model.predict(X_test)\n",
    "volatility_forecasts = scaler.inverse_transform(volatility_forecasts)\n",
    "\n",
    "volatility_forecasts = volatility_forecasts.squeeze()\n",
    "residuals = test_returns[20:] / volatility_forecasts\n",
    "\n",
    "sorted_ml_btc = threshold_picking(residuals)\n",
    "VaR_quantile = sorted_ml_btc[130]\n",
    "params = modeling(residuals, VaR_quantile)\n",
    "VaR_ml, ES_ml = prediction(params, residuals, VaR_quantile, level=0.01)\n",
    "\n",
    "print(VaR_ml)\n",
    "\n",
    "VaR_forecast = volatility_forecasts * -VaR_ml\n",
    "print(VaR_forecast)\n",
    "print(test_returns)\n",
    "\n",
    "# Align returns with predictions (assuming seq_length was used in training)\n",
    "#returns_aligned = test_returns[seq_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ca6d06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR_UC': 0.2805650111437501,\n",
       " 'p-value_UC': 0.5963311273876906,\n",
       " 'Reject_UC?': False,\n",
       " 'LR_IND': 0.3217520491944634,\n",
       " 'p-value_IND': 0.5705566251732743,\n",
       " 'Reject_IND?': False,\n",
       " 'LR_CC': 0.6023170603382135,\n",
       " 'p-value_CC': 0.7399604573914992,\n",
       " 'Reject_CC?': False,\n",
       " 'Violation Rate': 0.008853910477127398,\n",
       " 'Expected Rate': 0.01,\n",
       " 'Transition Matrix': [[1996, 18], [18, 0]]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "def conditional_coverage_test(actual_returns, var_forecast, alpha=0.05):\n",
    "    # Unconditional Coverage (UC) Test\n",
    "    actual_returns = np.asarray(actual_returns).flatten()\n",
    "    var_forecast = np.asarray(var_forecast).flatten()\n",
    "    \n",
    "    min_length = min(len(actual_returns), len(var_forecast))\n",
    "    actual_returns = actual_returns[:min_length]\n",
    "    var_forecast = var_forecast[:min_length]\n",
    "\n",
    "    violations = (actual_returns < var_forecast).astype(int) \n",
    "    #print(violations.head())\n",
    "    n = len(violations)\n",
    "    V = np.sum(violations)\n",
    "    p_uc = V / n\n",
    "    #print(actual_returns.head(), var_forecast, p_uc)\n",
    "    LR_uc = -2 * np.log((alpha**V * (1 - alpha)**(n - V))) + 2 * np.log((p_uc**V * (1 - p_uc)**(n - V)))\n",
    "    p_value_uc = 1 - chi2.cdf(LR_uc, df=1)\n",
    "    \n",
    "    # Independence (IND) Test\n",
    "    # Count transitions: n_ij = transitions from state i to j (0=no violation, 1=violation)\n",
    "    n00, n01, n10, n11 = 0, 0, 0, 0\n",
    "    for t in range(1, n):\n",
    "        prev, curr = violations[t-1], violations[t]\n",
    "        if prev == 0 and curr == 0: n00 += 1\n",
    "        elif prev == 0 and curr == 1: n01 += 1\n",
    "        elif prev == 1 and curr == 0: n10 += 1\n",
    "        elif prev == 1 and curr == 1: n11 += 1\n",
    "    \n",
    "    # Transition probabilities under H0 (independence)\n",
    "    p01 = n01 / (n00 + n01) if (n00 + n01) > 0 else 0\n",
    "    p11 = n11 / (n10 + n11) if (n10 + n11) > 0 else 0\n",
    "    p_ind = (n01 + n11) / (n00 + n01 + n10 + n11)  # Marginal violation probability\n",
    "    \n",
    "    # Likelihoods\n",
    "    L_ind = (1 - p_ind)**(n00 + n10) * p_ind**(n01 + n11)  # Independence\n",
    "    L_actual = (1 - p01)**n00 * p01**n01 * (1 - p11)**n10 * p11**n11  # Observed\n",
    "    \n",
    "    LR_ind = -2 * np.log(L_ind / L_actual) if L_actual > 0 else 0\n",
    "    p_value_ind = 1 - chi2.cdf(LR_ind, df=1)\n",
    "    \n",
    "    # Conditional Coverage (CC) Test\n",
    "    LR_cc = LR_uc + LR_ind\n",
    "    p_value_cc = 1 - chi2.cdf(LR_cc, df=2)\n",
    "    \n",
    "    # Decisions\n",
    "    reject_uc = p_value_uc < 0.05\n",
    "    reject_ind = p_value_ind < 0.05\n",
    "    reject_cc = p_value_cc < 0.05\n",
    "    \n",
    "    return {\n",
    "        \"LR_UC\": LR_uc,\n",
    "        \"p-value_UC\": p_value_uc,\n",
    "        \"Reject_UC?\": reject_uc,\n",
    "        \"LR_IND\": LR_ind,\n",
    "        \"p-value_IND\": p_value_ind,\n",
    "        \"Reject_IND?\": reject_ind,\n",
    "        \"LR_CC\": LR_cc,\n",
    "        \"p-value_CC\": p_value_cc,\n",
    "        \"Reject_CC?\": reject_cc,\n",
    "        \"Violation Rate\": V / n,\n",
    "        \"Expected Rate\": alpha,\n",
    "        \"Transition Matrix\": [[n00, n01], [n10, n11]],\n",
    "    }\n",
    "\n",
    "conditional_coverage_test(test_returns, VaR_forecast, alpha=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
