{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa0b18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.1.3\n",
      "Uninstalling numpy-2.1.3:\n",
      "  Successfully uninstalled numpy-2.1.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 180, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\pip\\_internal\\commands\\uninstall.py\", line 110, in run\n",
      "    uninstall_pathset.commit()\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\pip\\_internal\\req\\req_uninstall.py\", line 432, in commit\n",
      "    self._moved_paths.commit()\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\pip\\_internal\\req\\req_uninstall.py\", line 278, in commit\n",
      "    save_dir.cleanup()\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\pip\\_internal\\utils\\temp_dir.py\", line 173, in cleanup\n",
      "    rmtree(self._path)\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 291, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 381, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 327, in iter\n",
      "    raise retry_exc.reraise()\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 160, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\tenacity\\__init__.py\", line 384, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\pip\\_internal\\utils\\misc.py\", line 130, in rmtree\n",
      "    shutil.rmtree(dir, ignore_errors=ignore_errors, onerror=rmtree_errorhandler)\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\shutil.py\", line 759, in rmtree\n",
      "    return _rmtree_unsafe(path, onerror)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\shutil.py\", line 622, in _rmtree_unsafe\n",
      "    onerror(os.unlink, fullname, sys.exc_info())\n",
      "  File \"c:\\Users\\natha\\anaconda3\\Lib\\shutil.py\", line 620, in _rmtree_unsafe\n",
      "    os.unlink(fullname)\n",
      "PermissionError: [WinError 5] Access is denied: 'C:\\\\Users\\\\natha\\\\anaconda3\\\\Lib\\\\site-packages\\\\~-mpy.libs\\\\libscipy_openblas64_-c16e4918366c6bc1f1cd71e28ca36fc0.dll'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\n",
      "ERROR: Could not find a version that satisfies the requirement numpy==1.21.6 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4, 1.25.0, 1.25.1, 1.25.2, 1.26.0, 1.26.1, 1.26.2, 1.26.3, 1.26.4, 2.0.0, 2.0.1, 2.0.2, 2.1.0rc1, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.2.0rc1, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5, 2.2.6, 2.3.0rc1, 2.3.0)\n",
      "ERROR: No matching distribution found for numpy==1.21.6\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall -y numpy\n",
    "%pip install numpy==1.21.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86bb4e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\h5py\\__init__.py:36: UserWarning: h5py is running against HDF5 1.14.6 when it was built against 1.14.5, this may cause problems\n",
      "  _warn((\"h5py is running against HDF5 {0} when it was built against {1}, \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "import pyextremes as pyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17f3fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hill_estimator(data, k):\n",
    "    log_data = np.log(data[:k])\n",
    "    return (1/k) * np.sum(log_data) - np.log(data[k])\n",
    "\n",
    "def pickands_estimator(data, k):\n",
    "    if 4*k >= len(data):\n",
    "        return np.nan\n",
    "    return 1/np.log(2) * np.log((data[k] - data[2*k])/(data[2*k] - data[4*k]))\n",
    "\n",
    "def threshold_picking(data0):\n",
    "    data = -data0[data0 < 0]\n",
    "    thresholds = np.linspace(data.quantile(0.2), data.quantile(0.995), 200)\n",
    "    pyx.plot_mean_residual_life(data, thresholds=thresholds)\n",
    "    datas = np.sort(data)[::-1]\n",
    "    k_values = range(4, int(len(datas)/1.3))\n",
    "\n",
    "    hill_estimates = [hill_estimator(datas, k) for k in k_values]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(k_values, hill_estimates, 'b-')\n",
    "\n",
    "    pickands_estimates = [pickands_estimator(datas, k) for k in k_values]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(k_values, pickands_estimates, 'r-', label=\"Pickands' ξ\")\n",
    "    return datas\n",
    "\n",
    "def modeling(data0, u):\n",
    "    data = -data0[data0 < 0]\n",
    "    model = pyx.EVA(data)\n",
    "    model.get_extremes(method=\"POT\", threshold=u)\n",
    "    model.fit_model(distribution=\"genpareto\")\n",
    "    print(model.model)\n",
    "    model.plot_diagnostic()\n",
    "\n",
    "    params = model.model.fit_parameters\n",
    "    print(params)\n",
    "    xi = params['c']\n",
    "    sig = params['scale']\n",
    "    return xi, sig\n",
    "\n",
    "def prediction(params, data, u, level):\n",
    "    xi = params[0]\n",
    "    sig = params[1]\n",
    "    data = -data\n",
    "    p = level\n",
    "    n_total = len(data)\n",
    "    n_exceed = len([i for i in data if i > u])\n",
    "    F_u = n_exceed / n_total\n",
    "    print(F_u)\n",
    "    p_u = F_u / p\n",
    "    VaR = u + (sig / xi) * (p_u ** xi - 1)\n",
    "    ES = ES = (VaR + (sig - xi * u)) / (1 - xi)\n",
    "    return VaR, ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1582375",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2879, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Download S&P 500 data\n",
    "ticker = \"^GSPC\"\n",
    "data = yf.download(ticker, start=\"2014-01-01\")['Close']\n",
    "returns = np.log(data / data.shift(1)).dropna()\n",
    "\n",
    "# Create volatility proxy (squared returns)\n",
    "volatility = returns ** 2\n",
    "\n",
    "#Create volatility proxy (garch fitted)\n",
    "#from arch import arch_model\n",
    "#garch = arch_model(returns['^GSPC'], vol=\"GARCH\", p=1, q=1)\n",
    "#garch_fit = garch.fit(update_freq=5)\n",
    "#volatility = garch_fit.conditional_volatility\n",
    "\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_vol = scaler.fit_transform(volatility.values.reshape(-1, 1))\n",
    "\n",
    "# Split data 50:50\n",
    "split_idx = len(scaled_vol) // 2\n",
    "train_vol, test_vol = scaled_vol[:split_idx], scaled_vol[split_idx:]\n",
    "train_returns, test_returns = returns[:split_idx], returns[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67f90603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 20  # Lookback window\n",
    "X_train, y_train = create_sequences(train_vol, seq_length)\n",
    "X_test, y_test = create_sequences(test_vol, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "762f915c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - loss: 9.5208e-05 - mae: 0.0057 - val_loss: 0.0017 - val_mae: 0.0115\n",
      "Epoch 2/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.3045e-05 - mae: 0.0057 - val_loss: 0.0017 - val_mae: 0.0118\n",
      "Epoch 3/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.3400e-05 - mae: 0.0058 - val_loss: 0.0017 - val_mae: 0.0104\n",
      "Epoch 4/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.8302e-05 - mae: 0.0053 - val_loss: 0.0016 - val_mae: 0.0107\n",
      "Epoch 5/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 9.0741e-05 - mae: 0.0054 - val_loss: 0.0016 - val_mae: 0.0113\n",
      "Epoch 6/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 9.2734e-05 - mae: 0.0057 - val_loss: 0.0016 - val_mae: 0.0103\n",
      "Epoch 7/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.7657e-05 - mae: 0.0054 - val_loss: 0.0016 - val_mae: 0.0108\n",
      "Epoch 8/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 8.6978e-05 - mae: 0.0054 - val_loss: 0.0016 - val_mae: 0.0103\n",
      "Epoch 9/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.6046e-05 - mae: 0.0052 - val_loss: 0.0016 - val_mae: 0.0108\n",
      "Epoch 10/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.6652e-05 - mae: 0.0053 - val_loss: 0.0016 - val_mae: 0.0104\n",
      "Epoch 11/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.5808e-05 - mae: 0.0052 - val_loss: 0.0015 - val_mae: 0.0108\n",
      "Epoch 12/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.7813e-05 - mae: 0.0053 - val_loss: 0.0015 - val_mae: 0.0105\n",
      "Epoch 13/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.6443e-05 - mae: 0.0052 - val_loss: 0.0015 - val_mae: 0.0105\n",
      "Epoch 14/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.5093e-05 - mae: 0.0051 - val_loss: 0.0015 - val_mae: 0.0102\n",
      "Epoch 15/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.3730e-05 - mae: 0.0050 - val_loss: 0.0015 - val_mae: 0.0105\n",
      "Epoch 16/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 8.6325e-05 - mae: 0.0051 - val_loss: 0.0015 - val_mae: 0.0105\n",
      "Epoch 17/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 8.5554e-05 - mae: 0.0051 - val_loss: 0.0015 - val_mae: 0.0102\n",
      "Epoch 18/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 8.2638e-05 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0105\n",
      "Epoch 19/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 8.7137e-05 - mae: 0.0052 - val_loss: 0.0015 - val_mae: 0.0102\n",
      "Epoch 20/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.4799e-05 - mae: 0.0050 - val_loss: 0.0015 - val_mae: 0.0104\n",
      "Epoch 21/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.3326e-05 - mae: 0.0051 - val_loss: 0.0015 - val_mae: 0.0105\n",
      "Epoch 22/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.5174e-05 - mae: 0.0051 - val_loss: 0.0015 - val_mae: 0.0102\n",
      "Epoch 23/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.3362e-05 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0103\n",
      "Epoch 24/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.3479e-05 - mae: 0.0050 - val_loss: 0.0015 - val_mae: 0.0101\n",
      "Epoch 25/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 8.3242e-05 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0101\n",
      "Epoch 26/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.4322e-05 - mae: 0.0050 - val_loss: 0.0015 - val_mae: 0.0102\n",
      "Epoch 27/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.2432e-05 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0104\n",
      "Epoch 28/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.4585e-05 - mae: 0.0050 - val_loss: 0.0015 - val_mae: 0.0101\n",
      "Epoch 29/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.3782e-05 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0104\n",
      "Epoch 30/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.1469e-05 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0102\n",
      "Epoch 31/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 8.2697e-05 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0101\n",
      "Epoch 32/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.3895e-05 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0103\n",
      "Epoch 33/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 8.1900e-05 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0102\n",
      "Epoch 34/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.0829e-05 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0105\n",
      "Epoch 35/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.2515e-05 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0102\n",
      "Epoch 36/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.2219e-05 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0105\n",
      "Epoch 37/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.3174e-05 - mae: 0.0050 - val_loss: 0.0015 - val_mae: 0.0102\n",
      "Epoch 38/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 8.1142e-05 - mae: 0.0047 - val_loss: 0.0015 - val_mae: 0.0103\n",
      "Epoch 39/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.3015e-05 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0101\n",
      "Epoch 40/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.1747e-05 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0101\n",
      "Epoch 41/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.1298e-05 - mae: 0.0047 - val_loss: 0.0015 - val_mae: 0.0102\n",
      "Epoch 42/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 8.3470e-05 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0102\n",
      "Epoch 43/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.2827e-05 - mae: 0.0049 - val_loss: 0.0015 - val_mae: 0.0101\n",
      "Epoch 44/100\n",
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 8.2553e-05 - mae: 0.0048 - val_loss: 0.0015 - val_mae: 0.0101\n"
     ]
    }
   ],
   "source": [
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(64, activation='tanh', return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.3),\n",
    "        LSTM(32, activation='tanh'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "model = build_lstm_model(input_shape)\n",
    "\n",
    "# Train with early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960eb90e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6949062",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m volatility_forecasts \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      2\u001b[0m volatility_forecasts \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39minverse_transform(volatility_forecasts)\n\u001b[0;32m      4\u001b[0m residuals \u001b[38;5;241m=\u001b[39m test_returns[\u001b[38;5;241m20\u001b[39m:] \u001b[38;5;241m/\u001b[39m volatility_forecasts\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "volatility_forecasts = model.predict(X_test)\n",
    "volatility_forecasts = scaler.inverse_transform(volatility_forecasts)\n",
    "\n",
    "residuals = test_returns[20:] / volatility_forecasts\n",
    "#print(residuals.shape)\n",
    "\n",
    "residuals=residuals['^GSPC']\n",
    "\n",
    "sorted_ml_sp500 = threshold_picking(residuals)\n",
    "VaR_quantile = sorted_ml_sp500[150]\n",
    "params = modeling(residuals, VaR_quantile)\n",
    "VaR_ml, ES_ml = prediction(params, residuals, VaR_quantile, level=0.01)\n",
    "\n",
    "print(VaR_ml)\n",
    "\n",
    "VaR_forecast = volatility_forecasts * -VaR_ml\n",
    "print(VaR_forecast)\n",
    "print(test_returns)\n",
    "\n",
    "# Align returns with predictions (assuming seq_length was used in training)\n",
    "#returns_aligned = test_returns[seq_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "933cda16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LR_UC': 0.5286035096008561,\n",
       " 'p-value_UC': 0.46719456541542137,\n",
       " 'Reject_UC?': False,\n",
       " 'LR_IND': 1.6659320494401402,\n",
       " 'p-value_IND': 0.19680429000733923,\n",
       " 'Reject_IND?': False,\n",
       " 'LR_CC': 2.1945355590409963,\n",
       " 'p-value_CC': 0.3337818044684171,\n",
       " 'Reject_CC?': False,\n",
       " 'Violation Rate': 0.011980267794221282,\n",
       " 'Expected Rate': 0.01,\n",
       " 'Transition Matrix': [[1385, 16], [16, 1]]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "\n",
    "def conditional_coverage_test(actual_returns, var_forecast, alpha=0.05):\n",
    "    # Unconditional Coverage (UC) Test\n",
    "    actual_returns = np.asarray(actual_returns).flatten()\n",
    "    var_forecast = np.asarray(var_forecast).flatten()\n",
    "    \n",
    "    min_length = min(len(actual_returns), len(var_forecast))\n",
    "    actual_returns = actual_returns[:min_length]\n",
    "    var_forecast = var_forecast[:min_length]\n",
    "\n",
    "    violations = (actual_returns < var_forecast).astype(int) \n",
    "    #print(violations.head())\n",
    "    n = len(violations)\n",
    "    V = np.sum(violations)\n",
    "    p_uc = V / n\n",
    "    #print(actual_returns.head(), var_forecast, p_uc)\n",
    "    LR_uc = -2 * np.log((alpha**V * (1 - alpha)**(n - V))) + 2 * np.log((p_uc**V * (1 - p_uc)**(n - V)))\n",
    "    p_value_uc = 1 - chi2.cdf(LR_uc, df=1)\n",
    "    \n",
    "    # Independence (IND) Test\n",
    "    # Count transitions: n_ij = transitions from state i to j (0=no violation, 1=violation)\n",
    "    n00, n01, n10, n11 = 0, 0, 0, 0\n",
    "    for t in range(1, n):\n",
    "        prev, curr = violations[t-1], violations[t]\n",
    "        if prev == 0 and curr == 0: n00 += 1\n",
    "        elif prev == 0 and curr == 1: n01 += 1\n",
    "        elif prev == 1 and curr == 0: n10 += 1\n",
    "        elif prev == 1 and curr == 1: n11 += 1\n",
    "    \n",
    "    # Transition probabilities under H0 (independence)\n",
    "    p01 = n01 / (n00 + n01) if (n00 + n01) > 0 else 0\n",
    "    p11 = n11 / (n10 + n11) if (n10 + n11) > 0 else 0\n",
    "    p_ind = (n01 + n11) / (n00 + n01 + n10 + n11)  # Marginal violation probability\n",
    "    \n",
    "    # Likelihoods\n",
    "    L_ind = (1 - p_ind)**(n00 + n10) * p_ind**(n01 + n11)  # Independence\n",
    "    L_actual = (1 - p01)**n00 * p01**n01 * (1 - p11)**n10 * p11**n11  # Observed\n",
    "    \n",
    "    LR_ind = -2 * np.log(L_ind / L_actual) if L_actual > 0 else 0\n",
    "    p_value_ind = 1 - chi2.cdf(LR_ind, df=1)\n",
    "    \n",
    "    # Conditional Coverage (CC) Test\n",
    "    LR_cc = LR_uc + LR_ind\n",
    "    p_value_cc = 1 - chi2.cdf(LR_cc, df=2)\n",
    "    \n",
    "    # Decisions\n",
    "    reject_uc = p_value_uc < 0.05\n",
    "    reject_ind = p_value_ind < 0.05\n",
    "    reject_cc = p_value_cc < 0.05\n",
    "    \n",
    "    return {\n",
    "        \"LR_UC\": LR_uc,\n",
    "        \"p-value_UC\": p_value_uc,\n",
    "        \"Reject_UC?\": reject_uc,\n",
    "        \"LR_IND\": LR_ind,\n",
    "        \"p-value_IND\": p_value_ind,\n",
    "        \"Reject_IND?\": reject_ind,\n",
    "        \"LR_CC\": LR_cc,\n",
    "        \"p-value_CC\": p_value_cc,\n",
    "        \"Reject_CC?\": reject_cc,\n",
    "        \"Violation Rate\": V / n,\n",
    "        \"Expected Rate\": alpha,\n",
    "        \"Transition Matrix\": [[n00, n01], [n10, n11]],\n",
    "    }\n",
    "\n",
    "conditional_coverage_test(test_returns, VaR_forecast, alpha=0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
